# Sub-Component 3.7: Quality Assessor

## Purpose
Validate analysis quality, flag issues, calculate confidence scores, and trigger user intervention when needed.

---

## Requirements Gathering

### Question 1: Confidence Thresholds

**What confidence threshold should trigger user review?**

Options:
- **A. Strict:** Review if overall confidence < 0.7
- **B. Balanced:** Review if overall confidence < 0.5
- **C. Lenient:** Review only if confidence < 0.3
- **D. Component-based:** Different thresholds per component type

Considerations:
- Too strict = many interruptions
- Too lenient = poor quality passes through
- Component-based allows nuanced control

### Question 2: Auto-Retry Behavior

**Should we auto-retry low-confidence analyses?**

Options:
- **A. Never:** Always ask user first
- **B. Conditional:** Auto-retry if confidence 0.3-0.5
- **C. Always:** Retry once automatically, then ask
- **D. Smart:** Analyze failure type, retry if likely fixable

Considerations:
- Auto-retry adds cost
- Some issues won't fix with retry
- User may want to intervene with custom instructions

### Question 3: Blocking vs Warning Issues

**What issues should block downstream components vs just warn?**

Options:
- **A. Block all:** Any issue blocks Components 4-6
- **B. Critical only:** Only impossible timelines/duplicates block
- **C. Severity-based:** Score issues, block if total > threshold
- **D. Component-specific:** Different blockers per downstream component

Considerations:
- Blocking ensures quality but slows workflow
- Some issues may not affect all downstream tasks
- User may want to proceed despite warnings

### Question 4: Confidence Calibration

**How do we measure and calibrate confidence scores?**

Options:
- **A. Fixed:** Confidence = LLM-reported confidence
- **B. Validation-based:** Adjust based on validation passes
- **C. Historical:** Compare to past accurate analyses
- **D. Multi-factor:** LLM + validation + historical + heuristics

Considerations:
- LLM confidence often overestimated
- Historical calibration requires ground truth
- Multi-factor most accurate but complex

### Question 5: Issue Classification

**How should detected issues be classified?**

Options:
- **A. Binary:** Critical vs Non-critical
- **B. Severity levels:** Critical, Major, Minor, Info
- **C. Category + Severity:** Type of issue + severity
- **D. Impact-based:** Which downstream components affected

Considerations:
- More detail helps user understand
- Too many categories overwhelming
- Impact-based helps prioritize fixes

### Question 6: User Intervention Interface

**What should the intervention interface show?**

Options:
- **A. Summary:** Overall confidence + issue count
- **B. Detailed list:** All issues with explanations
- **C. Interactive:** User can fix issues inline
- **D. Guided:** Step-by-step wizard to address issues

Considerations:
- Summary may miss important issues
- Full detail may be overwhelming
- Interactive most powerful but complex

---

## Technical Considerations

### Quality Validation Pipeline

```typescript
interface QualityAssessor {
  // Run all validations
  assess(analysis: StorylineAnalysis): QualityReport;
  
  // Calculate confidence
  calculateConfidence(analysis: StorylineAnalysis): number;
  
  // Determine if blocking
  shouldBlock(report: QualityReport): boolean;
  
  // Generate user intervention request
  generateIntervention(report: QualityReport): InterventionRequest;
}

interface QualityReport {
  overallConfidence: number;
  overallValid: boolean;
  
  // Component scores
  components: {
    characters: ComponentScore;
    timeline: ComponentScore;
    relationships: ComponentScore;
    themes: ComponentScore;
  };
  
  // Issues found
  issues: QualityIssue[];
  
  // Recommendations
  recommendations: string[];
}

interface ComponentScore {
  confidence: number;
  valid: boolean;
  issues: QualityIssue[];
}

interface QualityIssue {
  id: string;
  type: string;
  severity: 'critical' | 'major' | 'minor' | 'info';
  description: string;
  affectedComponent: string;
  affectedEntities: string[];  // Character IDs, Event IDs
  suggestion: string;
  autoFixable: boolean;
}
```

### Confidence Calibration

```typescript
interface CalibrationData {
  // Historical accuracy vs reported confidence
  buckets: {
    confidenceRange: string;  // "0.0-0.2", "0.2-0.4", etc
    sampleCount: number;
    actualAccuracy: number;  // From user feedback
    reportedConfidence: number;
  }[];
  
  // Calibration function
  calibrate(rawConfidence: number): number;
}
```

---

## Decisions Recorded

| Question | Decision | Rationale |
|----------|----------|-----------|
| 1. Confidence Threshold | **B. Balanced (< 0.5)** | Reasonable balance between quality and interruptions |
| 2. Auto-Retry | **C. Always retry once** | Give system a chance to self-correct before bothering user |
| 3. Blocking Issues | **C. Severity-based scoring** | Nuanced decision-making based on cumulative impact |
| 4. Confidence Calibration | **D. Multi-factor** | Most accurate confidence scores |
| 5. Issue Classification | **D. Impact-based** | Prioritize based on downstream component effects |
| 6. Intervention Interface | **D. Guided wizard** | Best user experience for fixing issues |

### Multi-Factor Confidence Calibration

```typescript
function calculateCalibratedConfidence(
  analysis: StorylineAnalysis,
  validation: ValidationResult,
  historicalData: CalibrationData
): number {
  // Factor 1: LLM-reported confidence
  const llmConfidence = analysis.rawConfidence;
  
  // Factor 2: Validation pass rate
  const validationScore = calculateValidationScore(validation);
  
  // Factor 3: Historical accuracy for similar analyses
  const historicalScore = historicalData.getAccuracyForProfile({
    genre: analysis.genre,
    pageCount: analysis.pageCount,
    complexity: calculateComplexity(analysis)
  });
  
  // Factor 4: Heuristics
  const heuristicScore = calculateHeuristics(analysis);
  
  // Weighted combination
  const calibrated = 
    llmConfidence * 0.30 +
    validationScore * 0.35 +
    historicalScore * 0.25 +
    heuristicScore * 0.10;
  
  return Math.min(1.0, Math.max(0.0, calibrated));
}
```

### Severity-Based Blocking Threshold

```typescript
interface SeverityScoring {
  // Issue weights
  weights: {
    critical: 100;
    major: 40;
    minor: 10;
    info: 0;
  };
  
  // Block thresholds per downstream component
  blockThresholds: {
    anchorDetection: 150;    // Can tolerate some issues
    branchGeneration: 100;   // Needs high quality
    storyContinuation: 120;  // Moderate tolerance
  };
}

function calculateBlockScore(issues: QualityIssue[]): number {
  return issues.reduce((score, issue) => {
    return score + weights[issue.severity];
  }, 0);
}

function shouldBlockForComponent(
  score: number,
  component: 'anchorDetection' | 'branchGeneration' | 'storyContinuation'
): boolean {
  return score >= blockThresholds[component];
}
```

### Impact-Based Issue Classification

```typescript
interface ImpactAssessment {
  // Which downstream components are affected
  affects: {
    anchorDetection: boolean;
    branchGeneration: boolean;
    storyContinuation: boolean;
  };
  
  // Impact severity per component
  impactLevel: {
    anchorDetection: 'blocking' | 'degraded' | 'none';
    branchGeneration: 'blocking' | 'degraded' | 'none';
    storyContinuation: 'blocking' | 'degraded' | 'none';
  };
  
  // Recommended action
  recommendation: 'block_all' | 'block_some' | 'warn' | 'proceed';
}

// Example: Character inconsistency
const characterInconsistency: ImpactAssessment = {
  affects: {
    anchorDetection: true,      // May miss character decisions
    branchGeneration: true,     // Branches may not make sense
    storyContinuation: true     // Character voice inconsistent
  },
  impactLevel: {
    anchorDetection: 'degraded',
    branchGeneration: 'blocking',
    storyContinuation: 'degraded'
  },
  recommendation: 'block_some'  // Block branch generation, allow others
};
```

### Guided Intervention Wizard

```typescript
interface InterventionWizard {
  steps: InterventionStep[];
  
  // Step types
  steps: [
    {
      type: 'overview';
      title: 'Analysis Quality Review';
      show: ['overallConfidence', 'issueCount', 'affectedComponents'];
    },
    {
      type: 'critical_issues';
      title: 'Critical Issues';
      show: ['criticalIssueList'];
      actions: ['fix_inline', 'mark_resolved', 'retry_analysis'];
    },
    {
      type: 'component_impact';
      title: 'Impact on Features';
      show: ['anchorDetectionStatus', 'branchGenerationStatus', 'continuationStatus'];
      actions: ['proceed_anyway', 'fix_issues_first'];
    },
    {
      type: 'custom_instructions';
      title: 'Custom Analysis Instructions';
      show: ['textArea'];
      actions: ['retry_with_instructions', 'skip'];
    },
    {
      type: 'confirmation';
      title: 'Ready to Proceed?';
      show: ['finalQualityScore', 'recommendation'];
      actions: ['proceed', 'go_back', 'cancel'];
    }
  ];
}
```

### Auto-Retry Strategy

```typescript
async function autoRetryIfNeeded(
  analysis: StorylineAnalysis,
  qualityReport: QualityReport
): Promise<RetryResult> {
  const confidence = qualityReport.overallConfidence;
  
  // Auto-retry if in retry range
  if (confidence >= 0.3 && confidence < 0.5) {
    // Determine retry strategy based on issues
    const strategy = determineRetryStrategy(qualityReport.issues);
    
    // Retry with adjustments
    const retryResult = await retryAnalysis({
      mangaId: analysis.mangaId,
      adjustments: strategy.adjustments,
      focusAreas: strategy.focusAreas
    });
    
    // Return better of original or retry
    return compareAndReturnBetter(analysis, retryResult);
  }
  
  // Confidence too low or high enough, don't auto-retry
  return { shouldIntervene: true, analysis };
}
```

---

## Status: ✅ Interrogation Complete

**Next: Sub-Component 3.8 — Analysis Merger**

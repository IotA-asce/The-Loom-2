# Sub-Component 6.4: Voice Synthesizer

## Purpose
Maintain consistent character voices, dialogue styles, and narrative voice throughout generated content.

---

## Requirements Gathering

### Question 1: Speech Pattern Capture

**How do we capture and replicate subtle speech patterns?**

Options:
- **A. Example-based:** Provide dialogue samples in prompt
- **B. Rule-based:** Define rules (formal, uses big words, etc.)
- **C. Profile-based:** Character voice profile with traits
- **D. Embedding-based:** Vector representation of voice
- **E. Hybrid:** Combine multiple approaches

Considerations:
- Subtle patterns hard to capture in rules
- Examples help but may not cover all situations
- Need consistent replication across chapters

### Question 2: Character Voice Evolution

**Should characters' voices evolve as they develop?**

Options:
- **A. Fixed:** Voice stays identical throughout
- **B. Gradual:** Subtle shifts over time
- **C. Event-driven:** Major changes after significant events
- **D. Arc-based:** Pre-planned evolution path
- **E. Reactive:** Changes based on emotional state

Considerations:
- People do change how they speak
- But should remain recognizable
- Trauma, growth, new environments affect speech

### Question 3: Limited Dialogue Characters

**How do we handle characters with limited dialogue in original?**

Options:
- **A. Infer from narrative:** Derive voice from descriptions
- **B. Generic placeholder:** Use neutral voice
- **C. Archetype-based:** Match to similar characters
- **D. User-defined:** User provides voice guidance
- **E. Minimal presence:** Limit their dialogue

Considerations:
- Some characters have little source material
- But they may be important in branches
- Need to extrapolate plausibly

### Question 4: Similar Voice Differentiation

**What happens when two characters have similar voices?**

Options:
- **A. Emphasize differences:** Exaggerate distinctions
- **B. Merge slightly:** Combine into one voice
- **C. Contextual differentiation:** Different in different situations
- **D. User guidance:** Ask user how to distinguish
- **E. Accept similarity:** Some people do sound alike

Considerations:
- Similar voices confuse readers
- But forcing differences may feel artificial
- Context often helps differentiate

### Question 5: Narrative Voice Consistency

**How do we maintain consistent narrative voice?**

Options:
- **A. Style guide:** Written rules for narration
- **B. Example training:** Train on original manga prose
- **C. Real-time matching:** Check against original samples
- **D. Persona adoption:** Adopt "author persona"
- **E. Genre conventions:** Follow genre standard voice

Considerations:
- Narrative voice is distinct from character voices
- Should match original manga's storytelling style
- Genre affects expectations (noir vs. fantasy)

### Question 6: Internal Monologue Handling

**How should internal monologue be handled?**

Options:
- **A. Match external voice:** Same style as dialogue
- **B. Distinct internal voice:** Different from speech
- **C. Stream of consciousness:** Free-flowing thoughts
- **D. Structured thoughts:** Organized internal narrative
- **E. Original-matching:** Match source manga's approach

Considerations:
- People often think differently than they speak
- Some characters are filters, others are open books
- Original manga sets precedent

---

## Technical Considerations

### Voice Representation

```typescript
interface CharacterVoice {
  characterId: string;
  
  // Speech patterns
  patterns: {
    vocabulary: 'simple' | 'moderate' | 'complex' | 'varied';
    sentenceLength: 'short' | 'medium' | 'long' | 'varied';
    formality: 'casual' | 'neutral' | 'formal';
    dialect?: string;
  };
  
  // Verbal habits
  habits: {
    fillers: string[];      // "um", "like", "you know"
    catchphrases: string[];
    speechTics: string[];   // Repeated patterns
  };
  
  // Emotional expression
  emotions: {
    angry: string[];    // How they express anger
    sad: string[];
    happy: string[];
    // etc.
  };
  
  // Examples
  samples: string[];  // Dialogue samples from original
}

interface NarrativeVoice {
  // From Component 3 analysis
  descriptionDensity: 'minimal' | 'moderate' | 'rich';
  sentenceComplexity: 'simple' | 'complex' | 'varied';
  tense: 'past' | 'present';
  pov: 'first' | 'third-limited' | 'third-omniscient';
  tone: string[];
}
```

---

## Decisions Recorded

| Question | Decision | Rationale |
|----------|----------|-----------|
| 1. Speech Pattern Capture | **E. Hybrid** | Combine example-based, rule-based, and profile-based approaches |
| 2. Character Voice Evolution | **E. Reactive** | Changes based on current emotional state |
| 3. Limited Dialogue Characters | **D. User-defined** | User provides voice guidance for underdeveloped characters |
| 4. Similar Voice Differentiation | **D. User guidance** | Ask user how to distinguish similar-sounding characters |
| 5. Narrative Voice Consistency | **B. Example training** | Train on original manga prose samples |
| 6. Internal Monologue Handling | **E. Original-matching** | Match source manga's approach to thoughts |

### Hybrid Speech Pattern Capture

```typescript
interface HybridVoiceCapture {
  // Combine multiple approaches
  approaches: {
    // A: Example-based
    examples: {
      dialogueSamples: string[];  // From original manga
      weight: 0.4;
    };
    
    // B: Rule-based
    rules: {
      formality: 'casual' | 'formal';
      vocabularyLevel: 'simple' | 'complex';
      sentenceStructure: 'short' | 'long';
      weight: 0.3;
    };
    
    // C: Profile-based
    profile: {
      traits: string[];
      habits: string[];
      emotionalExpressions: Record<string, string[]>;
      weight: 0.3;
    };
  };
  
  // Synthesis
  synthesize: () => VoiceProfile;
}
```

### Reactive Voice Evolution

```typescript
interface ReactiveVoiceEvolution {
  // Voice changes based on emotional state
  trigger: 'emotional-state';
  
  adaptations: {
    angry: {
      shorterSentences: true;
      harsherWords: true;
      lessFiller: true;
    };
    sad: {
      slowerPace: true;
      softerWords: true;
      morePauses: true;
    };
    excited: {
      fasterPace: true;
      exclamations: true;
      runOnSentences: true;
    };
    confident: {
      assertiveTone: true;
      directSpeech: true;
      lessHesitation: true;
    };
  };
  
  // Core voice remains recognizable
  coreIdentity: 'preserved';
}
```

### User-Defined Voices for Minor Characters

```typescript
interface UserDefinedMinorCharacterVoices {
  // Detect limited-dialogue characters
  detectLimited: (character: Character) => boolean;
  
  // Prompt user for guidance
  promptUser: (character: Character) => UserVoiceInput;
  
  // Input options
  inputMethods: {
    describe: 'Describe how they speak...';
    compare: 'They sound like [famous character]...';
    sample: 'Write example dialogue...';
    archetype: 'Select archetype: [shy] [gruff] [eloquent]...';
  };
  
  // Store for future use
  storeDefinition: (characterId: string, voice: VoiceDefinition) => void;
}
```

### User-Guided Differentiation

```typescript
interface UserGuidedDifferentiation {
  // Detect similar voices
  detectSimilarity: (charA: Character, charB: Character) => SimilarityScore;
  
  // If similarity > threshold
  threshold: 0.8;
  
  // Prompt user
  prompt: {
    message: 'These characters sound similar. How should we distinguish them?';
    options: {
      emphasizeA: 'Make Character A more [formal/casual/etc.]';
      emphasizeB: 'Make Character B more [formal/casual/etc.]';
      addQuirkA: 'Give Character A a speech quirk';
      addQuirkB: 'Give Character B a speech quirk';
      custom: 'Describe the difference...';
    };
  };
}
```

### Example-Based Narrative Voice Training

```typescript
interface ExampleBasedNarrativeVoice {
  // Train on original manga prose
  training: {
    source: 'original-manga';
    samples: string[];  // 5-10 paragraphs of narration
    
    extractFeatures: {
      sentenceStructure: 'analyze patterns';
      vocabulary: 'word choice preferences';
      rhythm: 'pacing and flow';
      descriptionStyle: 'how details are presented';
    };
  };
  
  // Apply to generation
  application: {
    matchSentenceLength: true;
    matchVocabularyLevel: true;
    matchDescriptionDensity: true;
    matchTone: true;
  };
}
```

### Original-Matching Internal Monologue

```typescript
interface OriginalMatchingInternalMonologue {
  // Analyze how original handles thoughts
  analysis: {
    style: 'direct' | 'indirect' | 'stream-of-consciousness';
    formatting: 'italics' | 'quotes' | 'no-markers';
    frequency: 'rare' | 'moderate' | 'frequent';
    depth: 'surface' | 'deep';
  };
  
  // Match in generated content
  match: {
    style: 'same-as-original';
    frequency: 'same-as-original';
    depth: 'same-as-original';
  };
  
  // Examples from analysis:
  // Original: Direct thoughts in italics, moderate frequency
  // Generated: Same approach
}
```

---

## Status: ✅ Interrogation Complete

**Next: Sub-Component 6.5 — Continuity Guardian**
